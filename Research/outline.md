# Research Proposal
## By- Anuja Yawar
### Topic:   ***Analysis of Cloud Computing Algorithms***

>Cloud computing is the fastest growing technology, offers various services over the internet. This paper will cover topics regarding the framework of distributed computing, architecture and security provided by cloud computing. In this paper, I  will be discussing the various benefits and major security challenges of cloud computing, it is also going to highlights the various cryptographic encryption algorithms as the major solution of security challenges. Moreover, I will be covering the efficiency of the each algorithm discussed in the paper.

## **Hook**

### **Initial proposal - presented above** <br>
### Professor's suggestion:
- Read time of paper - 5 minutes
- "framework for Distributed Computing" so many - pick one
- "cryptographic encryption algorithms" - so many - don't include (stick to time of read)
<br>
### **Modified proposal**
- Picking Hadoop and Spark as the framewrok for distributed computing.
- Comparing the performance analysis
- totally eliminating the cryptographic encryption algorthims

**Progress Report:**
> - Topics covered so far,
>1. Introduction
>2. Introducing the concept of distributed computing. 
>3. What are the benefits of distributed computing. 

## **Introduction**
In the last few decades there is tremedous growth in data emphasize big data storage and management issues. New programming platoform like Hadoop and Spark has been a big game changer. Hadoop framework is based on MapReduce distributed file system where as Spark is a recently developed big data management framework.In this research paper, a comparison between the framework of Hadoop and Spark will be covered based on their architecture, performance, cost, data preprocessing etc.

### **Distributed Computing**

Distributed computer system consists of multiple software components that are on multiple computers but run as a single system. The computers can be physically closed and are connected by a local network or they can be placed in geographically different places by wide area network. Distributed computing consists of possible configurations like mainframes, personal computers, workstations, minicomputers and so on. 
### Why distributed computing? 
- Scalability and Modular Growth - Distributed systems are inherently scalable as they work across different machines and scale horizontally.
- Fault Tolerance and Redundancy - Distributed systems stay put even if one or more nodes/sites stop working (performance demand on the remaining nodes would go up)
- Low Latency - Distributed systems allow the traffic to hit a node thatâ€™s closest, resulting in low latency and better performance.
- Cost Effective - Their initial cost is higher than standalone systems, but only up to a certain point after which they are more about economies of scale

**to be covered in upcoming week**
1. Frameworks explaination- Hadoop and Spark
2. Comparison of architecture of Hadoop and Spark
3. Analysis of both the frame work- performance, cost, usage, etc.


